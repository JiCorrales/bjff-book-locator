# Chatbot de Biblioteca (Lia)

Este documento describe la arquitectura, uso y pruebas del chatbot de la biblioteca (Lia), desarrollado para comprender consultas en espa√±ol, responder con claridad y recibir retroalimentaci√≥n de los usuarios.

## Capacidades

- Comprensi√≥n de consultas en espa√±ol mediante:
  - Modelo conversacional remoto (OpenAI) si est√° configurado.
  - Motor NLP local con reglas en espa√±ol como respaldo.
- Respuestas claras y concisas, con listas breves y orientaci√≥n al portal.
- Manejo de diferentes tipos de preguntas: informativas, t√©cnicas y administrativas.
- Sistema de retroalimentaci√≥n con botones üëç/üëé para mejorar continuamente.
- Manejo de errores: respuestas amistosas cuando el asistente no est√° disponible o no comprende.
- Rendimiento: timeout de 2 segundos en peticiones para respuestas r√°pidas.
- Escalabilidad: backend Express, endpoints idempotentes y sanitizaci√≥n de entrada.

## Arquitectura

- Frontend Angular
  - `ChatbotService`: gestiona conversaci√≥n, preferencias y llamadas a API con `timeout(2000)`.
  - `LibraryChatbotComponent`: UI con sugerencias, nivel de detalle y botones de feedback.
  - Endpoint feedback: `/api/chatbot/feedback`.
- Backend Express (TypeScript)
  - `LibraryAssistantService`: integra OpenAI si `OPENAI_API_KEY` est√° disponible.
  - `LocalNlpAssistantService`: fallback inmediato con intents en espa√±ol.
  - Router `/api/chatbot/conversation`: sanitiza conversaci√≥n y responde con el asistente disponible.
  - Router `/api/chatbot/feedback`: registra valoraciones en memoria.

## Endpoints

- `POST /api/chatbot/conversation`
  - Body: `{ conversation: Array<{ role: 'user'|'assistant', content: string }> }`
  - Respuesta: `{ message: { role: 'assistant', content: string } }`
- `POST /api/chatbot/feedback`
  - Body: `{ assistantMessage?: string, rating: 'up'|'down', comment?: string }`
  - Respuesta: `{ message: 'Feedback registrado.' }`

## Configuraci√≥n

Variables de entorno en backend (`.env`):

- `OPENAI_API_KEY`: clave para activar el modelo remoto (opcional).
- `OPENAI_MODEL`, `OPENAI_TEMPERATURE`, `OPENAI_MAX_OUTPUT_TOKENS`: par√°metros del modelo.

Si no se configura `OPENAI_API_KEY`, se usa autom√°ticamente el motor NLP local.

## Uso (Manual B√°sico)

1. Abrir el widget ‚ÄúHablar con Lia‚Äù en la esquina inferior derecha.
2. Ajustar el ‚ÄúNivel de detalle‚Äù si desea respuestas m√°s concisas o desarrolladas.
3. Escribir la consulta o elegir una sugerencia (‚ÄúBuscar libro por c√≥digo‚Äù, etc.).
4. Enviar y esperar la respuesta; si fue √∫til, marcar üëç/üëé.
5. Reiniciar la conversaci√≥n en cualquier momento con el bot√≥n ‚ÄúReiniciar‚Äù.

## Pruebas

- Frontend: `ChatbotService` incluye pruebas de saludo y feedback.
- Backend: `LocalNlpAssistantService` probado con intents principales y fallback.

## Notas de Dise√±o

- El motor NLP local cubre intents m√°s comunes en la biblioteca; puede ampliarse con m√°s patrones.
- El sistema de feedback actual almacena datos en memoria; puede integrarse con base de datos para an√°lisis.
- La UI prioriza accesibilidad: indicadores de estado, `aria-label`s y controles claros.

## Pr√≥ximos Pasos

- Persistir feedback en base de datos y construir panel de an√°lisis.
- A√±adir comprensi√≥n de idioma y respuesta en el idioma del usuario.
- Expandir intents t√©cnicos/administrativos y enlaces profundos al portal.